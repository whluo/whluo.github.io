<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenhan Luo - List of Publications</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>


    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Wenhan Luo - List of Publications</name>
              </p>
              <p style="text-align:center">
                (* indicates equal contribution, + indicates intern working with me)
              </p>           

        
            </td>
          </tr>
        </tbody></table>







<div class="paper">


<ol reversed>

  <li><papertitle>APPTracker: Improving Tracking Multiple Objects in Low-Frame-Rate Videos</papertitle>,
    <br>T. Zhou, W. Luo, Z. Shi, J. Chen, Q. Ye,<br>
    <i>The 30th ACM International Conference on Multimedia (ACM MM), 2022.</i>
    <br>
      [<a href="">PDF</a>]
      [<a href="">Code</a>]
      <p></p>
      </li>


  <li><papertitle>Four-player GroupGAN for Weak Expression Recognition via Latent Expression Magnification</papertitle>,
    <br>W. Niu, K. Zhang, D. Li, W. Luo,<br>
    <i>Knowledge-Based Systems, 2022.</i>
    <br>
    [<a href="papers/GroupGAN_KBS.pdf">PDF</a>]
    <p></p></li>


  <li><papertitle>EDFace-Celeb-1M: Benchmarking Face Hallucination with a Million-scale Dataset</papertitle>,
    <br>K. Zhang, D. Li, W. Luo, J. Liu, J. Deng, W. Liu, S. Zafeiriou,<br>
    <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), 2022.</i>
    <br>
    [<a href="https://arxiv.org/abs/2110.05031">PDF</a>]
    [<a href="https://github.com/HDCVLab/EDFace-Celeb-1M">Github</a>]
    <p></p></li>



  <li><papertitle>Deep Image Deblurring: A Survey</papertitle>,
    <br>
    K. Zhang, W. Ren, W. Luo, W. Lai, B. Stenger, M. Yang, H. Li,
    <br>
    <em>International Journal of Computer Vision (IJCV), 2022.</em>
    <br>
    [<a href="https://arxiv.org/pdf/2201.10700.pdf">PDF</a>]
    <p></p>
  </li>


  <li><papertitle>Beyond Monocular Deraining: Parallel Stereo Deraining Network Via Semantic Prior</papertitle>,
    <br>
    K. Zhang+, W. Luo, Y. Yu, W. Ren, F. Zhao, C. Li, L. Ma, W. Liu, H. Li,
    <br>
    <em>International Journal of Computer Vision (IJCV), 2022.</em>
    <br>
    [<a href="papers/MonocularDeraining_IJCV.pdf">PDF</a>]
    [<a href="https://github.com/HDCVLab/Stereo-Image-Deraining">Github</a>]
    <p></p>
  </li>

  
  <li><papertitle>Aesthetic Text Logo Synthesis via Content-aware Layout Inferring</papertitle>,
    <br>Y. Wang+, Guo Pu, W. Luo, Y. Wang, P. Xiong, H. Kang, Z. Lian,<br>
    <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2022.</i>
    <br>
    [<a href="https://arxiv.org/abs/2204.02701">PDF</a>]
    [<a href="https://github.com/yizhiwang96/TextLogoLayout">Dataset/Code</a>]
    <p></p></li>



  <li><papertitle>Enhanced Spatio-Temporal Interaction Learning for Video Deraining: A Faster and Better Framework</papertitle>,
    <br>K. Zhang+, D. Li, W. Luo, W. Ren, W. Liu,<br>
    <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), 2022.</i>
    <br>
    [<a href="https://arxiv.org/abs/2103.12318">arXiv</a>]
    [<a href="https://github.com/HDCVLab/Enhanced-Spatio-Temporal-Interaction-Learning-for-Video-Deraining">Dataset/Code</a>]
    <p></p></li>

    


  <li><papertitle>Deep Robust Image Deblurring via Blur Distilling and Information Comparison in Latent Space</papertitle>,
    <br>W. Niu, K. Zhang, W. Luo, Y. Zhong, H. Li,<br>
    <i>Neurocomputing, vol. 466, pp. 69-79, 2021.</i>
    <br>
    [<a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231221013771">PDF</a>]
    <p></p></li>

  

  <li><papertitle>Dual Attention-in-Attention Model for Joint Rain Streak and Raindrop Removal</papertitle>,
    <br>K. Zhang+, D. Li, W. Luo, W. Ren,<br>
    <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
    <br>
    [<a href="https://arxiv.org/pdf/2103.07051.pdf">PDF</a>]
    <p></p></li>


  <li><papertitle>Deep Dense Multi-scale Network for Snow Removal Using Semantic and Geometric Priors</papertitle>,
    <br>K. Zhang+, R. Li, Y. Yu, W. Luo, C. Li,<br>
    <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
    <br>
    [<a href="https://arxiv.org/abs/2103.11298">PDF</a>]
    [<a href="https://github.com/HDCVLab/Deep-Dense-Multi-scale-Network-for-Snow-Removal">Dataset/Code</a>]
    <p></p></li>



    <li><papertitle>Benchmarking Ultra-High-Definition Image Super-resolution</papertitle>,
      <br>K. Zhang+, D. Li, W. Luo, W. Ren, B. Stenger, W. Liu, H. Li, M. Yang,<br>
      <i>Proc. of International Conference on Computer Vision (ICCV), 2021.</i>
      <br>
      [<a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Zhang_Benchmarking_Ultra-High-Definition_Image_Super-Resolution_ICCV_2021_paper.pdf">PDF</a>]
      [<a href="https://github.com/HDCVLab/Benchmarking-Ultra-High-Definition-Image-Super-resolution">Dataset</a>]
      <p></p></li>



  <li><papertitle>Blind Motion Deblurring Super-Resolution: When Dynamic Spatio-Temporal Learning Meets Static Image Understanding</papertitle>,
    <br>W. Niu, K. Zhang, W. Luo, Y. Zhong,<br>
    <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
    <br>
    [<a href="https://arxiv.org/abs/2105.13077">PDF</a>]
    <p></p></li>


  <li><papertitle>LAGA-Net: Local-And-Global Attention Network for Skeleton Based Action Recognition</papertitle>,
    <br>R. Xia, Y. Li, W. Luo,<br>
    <i>IEEE Transactions on Multimedia (TMM), 2021.</i>
    <br>
    [<a href="https://ieeexplore.ieee.org/abstract/document/9447926">PDF</a>]
    <p></p></li>  

  

  <li><papertitle>Towards Distraction-Robust Active Visual Tracking</papertitle>,
    <br>F. Zhong+, P. Sun, W. Luo, T. Yan, Y. Wang,<br>
    <i>International Conference on Machine Learning (ICML), 2021.</i>
    <br>
    [<a href="https://arxiv.org/abs/2106.10110">PDF</a>]
    [<a href="https://github.com/zfw1226/active_tracking_rl/tree/distractor">Code</a>]
    <p></p></li>  

  <li><papertitle>Single Image Dehazing via Dual-Path Recurrent Network</papertitle>,
    <br>X. Zhang, R. Jiang, T. Wang and W. Luo,<br>
    <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
    <br>
    [<a href="https://ieeexplore.ieee.org/document/9435998">PDF</a>]
    <p></p></li>  


  <li><papertitle>Liquid Warping GAN with Attention: A Unified Framework for Human Image Synthesis</papertitle>,
  <br>W. Liu+, Z. Piao, Z. Tu, W. Luo, L. Ma, and S. Gao,<br>
  <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), 2021.</i>
  <br>
 [<a href="https://arxiv.org/abs/2011.09055">PDF</a>]
 [<a href="https://github.com/iPERDance/iPERCore">Code</a>]
  <p></p></li>


  <li><papertitle>Multidimensional Local Binary Pattern for Hyperspectral Image Classification</papertitle>,
    <br>Y. Li, H. Tang, W. Xie, and W. Luo,<br>
    <i>IEEE Trans. on Geoscience and Remote Sensing, 2021.</i>
    <br>
    [<a href="papers/TGRS21_MDLBP.pdf">PDF</a>]
    <p></p></li> 



  <li><papertitle>Disentangled Feature Networks for Facial Portraits Generation</papertitle>,
    <br>K. Zhang+, W. Luo, L. Ma, W. Ren, and H. Li,<br>
    <i>IEEE Transactions on Multimedia (TMM), 2021.</i>
    <br>
    [<a href="papers/TMM_disentangled.pdf">PDF</a>]
    <p></p></li> 

  <li><papertitle>Multiple Object Tracking: A Literature Review</papertitle>,
  <br>W. Luo, J. Xing, A. Milan, X. Zhang, W. Liu, and T-K. Kim,<br>
  <i>Artificial Intelligence, 2021.</i>
  <br>
  [<a href="papers/MOT_review_published.pdf">PDF</a>]
  <p></p></li>  


  <li><papertitle>Multi-level Fusion and Attention-guided CNN for Image Dehazing</papertitle>,
    <br>X. Zhang, T. Wang, W. Luo, P. Huang,<br>
    <i>IEEE Trans. on Circuits and Systems for Video Technology (TCSVT), 2021.</i>
    <br>
    [<a href="papers/image_dehazing_csvt19.pdf">PDF</a>]
    <p></p></li>  

  
  <li><papertitle>Coupled Network for Robust Pedestrian Detection with Gated Multi-Layer Feature Extraction and Deformable Occlusion Handling</papertitle>,
    <br>T. Liu+, W. Luo, L. Ma, J. Huang, T. Stathaki and T. Dai,<br>
    <i>IEEE Trans. on Image Processing (TIP), 2021.</i>
    <br>
    [<a href="papers/TIP2020_detection.pdf">PDF</a>]
    <p></p></li>  


    <li><papertitle>STFlow: Self-Taught Optical Flow Estimation Using Pseudo Labels</papertitle>,
      <br>Z. Ren+, W. Luo, J. Yan, X. Yang, A. Yuille, H. Zha,<br>
      <i>IEEE Trans. on Image Processing (TIP), 2020.</i>
      <br>
      [<a href="papers/TIP2020_flow.pdf">PDF</a>]
      <p></p></li>  


<li><papertitle>Every Moment Matters: Detail-Aware Networks to Bring a Blurry Image Alive</papertitle>,
  <br>K. Zhang+, W. Luo, B. Stenger, W. Ren, L. Ma, H. Li<br><em>The 28th ACM International Conference on Multimedia (ACM MM), 2020. (<strong>Oral</strong>)</em><br>
    [<a href="https://dl.acm.org/doi/pdf/10.1145/3394171.3413929">PDF</a>]
    <p></p>
    </li>


    <li><papertitle>Distractor-Aware Discrimination Learning for Online Multiple Object Tracking</papertitle>,
      <br>Z. Zhou, W. Luo, Q. Wang, J. Xing, W. Hu,<br>
      <i>Pattern Recognition, 2020.</i>
      <br>
      [<a href="papers/PR2020_DDLMOT.pdf">PDF</a>]
      [<a href="https://github.com/ZongweiZhou1/DDLTracker">Code</a>]
      <p></p></li>  

      <li><papertitle>TSSLBP: Tensor-based Spatialâ€“Spectral Local Binary Pattern</papertitle>,
        <br>Y. Li, H. Tang, L. Fan, W. Luo,<br>
        <i>Journal of Applied Remote Sensing, 2020.</i>
        <br>
        <p></p></li>  


            <li><papertitle>Beyond Monocular Deraining: Stereo Image Deraining via Semantic Understanding</papertitle>,
              <br>
              K. Zhang+, W. Luo, W. Ren, J. Wang, F. Zhao, L. Ma, H. Li,
              <br>
              <em>European Conference on Computer Vision (ECCV), UK, 2020.</em>
              <br>
              [<a href="https://link.springer.com/chapter/10.1007/978-3-030-58583-9_5">PDF</a>]
              [<a href="https://pan.baidu.com/s/1T2UplwARbLS5apIQiAnEXg">Dataset (zzkd)</a>]
              [<a href="https://pan.baidu.com/s/1cCqYg2Au8yhEXkypPhkszA">Code (ehl2)</a>]
              [<a href="https://pan.baidu.com/s/1BV2-TPL5GiTlDbxjSR0qyg">Results (yb4y)</a>]
              [<a href="https://github.com/HDCVLab/Beyond-Monocular-Deraining">Github</a>]
              <p></p>
            </li>

            <li><papertitle>Deblurring by Realistic Blurring</papertitle>,
            <br>
            K. Zhang+, W. Luo, Y. Zhong, L. Ma, B. Stenger, W. Liu, H. Li,
            <br>
            <em>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2020. (<strong>Oral</strong>)</em>
            <br>
            [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Zhang_Deblurring_by_Realistic_Blurring_CVPR_2020_paper.pdf">PDF</a>]
            [<a href="https://github.com/HDCVLab/Deblurring-by-Realistic-Blurring">Dataset/Code</a>]
            <p></p></li>



          <li><papertitle>Fine-grained Image-to-Image Transformation towards Visual Recognition</papertitle>,
            <br>
            W. Xiong, Y. He, Y. Zhang, W. Luo, L. Ma, J. Luo,
            <br>
            <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2020.</i>
            <br>
            [<a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Xiong_Fine-Grained_Image-to-Image_Transformation_Towards_Visual_Recognition_CVPR_2020_paper.pdf">PDF</a>]
            [<a href="https://wxiong.me/finegrain/">Project Page</a>]
            <p></p></li>


            <li><papertitle>Video Deblurring via Spatiotemporal Pyramid Network and Adversarial Gradient Prior</papertitle>,
              <br>T. Wang, X. Zhang, R. Jiang, L. Zhao, H. Chen, W. Luo,<br>
              <i>Computer Vision and Image Understanding (CVIU), 2021.</i>
              <br>
              [<a href="papers/cviu103135_final.pdf">PDF</a>]
              <p></p></li> 

              <li><papertitle>AD-VAT+: An Asymmetric Dueling Mechanism for Learning and Understanding Visual Active Tracking</papertitle>,
                <br>F. Zhong+, P. Sun, W. Luo, T. Yan, Y. Wang,<br>
                <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), 2019.</i>
                <br>
                [<a href="papers/AD_VAT_TPAMI.pdf">PDF</a>]
                [<a href="https://github.com/zfw1226/active_tracking_rl">Code</a>]
                [<a href="https://drive.google.com/file/d/1KKswxtaZlcHUYJmMEmAGnvXXrVxZ5rQQ/view">Demo</a>]
                [<a href="https://github.com/zfw1226/gym-unrealcv">Dataset</a>]
                <p></p></li>  


            <li><papertitle>Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis</papertitle>,
              <br>
              W. Liu+, Z. Piao, J. Min, W. Luo, L. Ma, S. Gao,
              <br>
              <i>Proc. of International Conference on Computer Vision (ICCV), Korea, 2019.</i>
              <br>
              [<a href="https://openaccess.thecvf.com/content_ICCV_2019/papers/Liu_Liquid_Warping_GAN_A_Unified_Framework_for_Human_Motion_Imitation_ICCV_2019_paper.pdf">PDF</a>]
              [<a href="https://svip-lab.github.io/project/impersonator.html">Project Page</a>]
              [<a href="https://github.com/svip-lab/impersonator">Code</a>]
              [<a href="https://svip-lab.github.io/dataset/iPER_dataset.html">Dataset</a>]
              <p></p></li>


              <li><papertitle>Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video</papertitle>,
                <br>
                Z. Chen+, L. Ma, W. Luo, K.-Y. K. Wong,
                <br>
                <i>The 57th Annual Meeting of the Association for Computational Linguistics (ACL), Italy, 2019. (<strong>Oral</strong>)</i>
                <br>
                [<a href="papers/ACL2019_WSSTG.pdf">PDF</a>]
                [<a href="https://github.com/zfchenUnique/WSSTG">Code</a>]
                <p></p></li>


                <li><papertitle>Face Anti-Spoofing: Model Matters, So Does Data</papertitle>,
                  <br>
                  X. Yang*, W. Luo*, L. Bao, Y. Gao, D. Gong, S. Zheng, Z. Li, W. Liu,
                  <br>
                  <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2019.</i>
                  <br>
                  [<a href="papers/CVPR2019_1863.pdf">PDF</a>]
                  <p></p></li>


                  <li><papertitle>Learning Joint Gait Representation via Quintuplet Loss Minimization</papertitle>,
                    <br>
                    K. Zhang+, W. Luo, L. Ma, W. Liu, H. Li,
                    <br>
                    <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2019. (<strong>Oral</strong>)</i>
                    <br>
                    [<a href="papers/CVPR2019_1617.pdf">PDF</a>]
                    <p></p></li>


                    <li><papertitle>Residual Regression with Semantic Prior for Crowd Counting</papertitle>,
                      <br>J. Wan+, W. Luo, B. Wu, A. Chan, W Liu,<br>
                      <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2019.</i>
                      <br>
                      [<a href="papers/CVPR2019_1875.pdf">PDF</a>]
                      [<a href="http://visal.cs.cityu.edu.hk/research/residual_regression_counting/">Project Page</a>]
                      [<a href="https://github.com/jia-wan/ResidualRegression-pytorch">Code</a>]
                      <p></p></li>
              

                      
                    <li><papertitle>Learning to Compose Dynamic Tree Structures for Visual Contexts</papertitle>,
                      <br>K. Tang+, H. Zhang, B. Wu, W. Luo, W. Liu,<br>
                      <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2019. (<strong>Oral & Best Paper Finalist</strong>)</i>
                      <br>
                      [<a href="https://arxiv.org/abs/1812.01880">arXiv</a>]
                      [<a href="https://github.com/KaihuaTang/VCTree-Scene-Graph-Generation">Code</a>]
                      <p></p></li>

    
                      <li><papertitle>Bi-Real Net: Binarizing Deep Network towards Real-Network Performance</papertitle>,
                        <br>Z. Liu+, W. Luo, B. Wu, X. Yang, W. Liu, K-T. Cheng,<br>
                        <i>International Journal of Computer Vision (IJCV), 2020.</i>
                        <br>
                        [<a href="https://link.springer.com/epdf/10.1007/s11263-019-01227-8?author_access_token=NdkBwSULpW7AE0CplLNsQ_e4RwlQNchNByi7wbcMAY4zuJMqwdUG6xUI3neO68YE0HVQMhRVozqO0gNwgOgvcveiex4uWiK7xaxvf-r1oNmb1LdDYZoo4NSrjwdzGTAXBVNftZN-W65j0eIc1yxdag%3D%3D">PDF</a>]
                        [<a href="https://arxiv.org/abs/1811.01335">arXiv</a>]
                        [<a href="https://github.com/liuzechun/Bi-Real-net">Code</a>]
                        <p></p></li>  



                    <li><papertitle>AD-VAT: An Asymmetric Dueling Mechanism for Learning Visual Active Tracking</papertitle>,
                      <br>F. Zhong+, P. Sun, W. Luo, T. Yan, Y. Wang,<br>
                      <i>International Conference on Learning Representations (ICLR), New Orleans, USA, 2019.</i>
                      <br>
                      [<a href="https://openreview.net/forum?id=HkgYmhR9KX">OpenReview Link</a>]
                      [<a href="https://github.com/zfw1226/active_tracking_rl">Code</a>]
                      [<a href="https://github.com/zfw1226/gym-unrealcv">Dataset</a>]
                      <p></p></li>     
                      

                  

                        <li><papertitle>End-to-end Active Object Tracking and Its Real-world Deployment via Reinforcement Learning</papertitle>,
                          <br>W. Luo*, P. Sun*, F. Zhong*, W. Liu, T. Zhang and Y. Wang,<br>
                          <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), vol. 42, pp. 1317-1332, 2019.</i>
                          <br>
                          [<a href="https://arxiv.org/abs/1808.03405">arXiv</a>]
                          [<a href="https://sites.google.com/site/whluoimperial/active_tracking_icml2018">Project Page</a>]
                          [<a href="https://sites.google.com/site/whluoimperial/active_tracking_icml2018">Code</a>]
                          <p></p></li> 


                        <li><papertitle>Cousin Network Guided Sketch Recognition via Latent Attribute Warehouse</papertitle>,
                          <br>K. Zhang+, W. Luo, L. Ma, H. Li,<br>
                          <i>Proc. of the Association for the Advancement of Artificial Intelligence (AAAI), Hawaii, USA, 2019. (<strong>Spotlight</strong>)</i>
                          <br>
                          [<a href="papers/AAAI2019_camera_ready.pdf">PDF</a>]
                          <p></p></li>  

                          <li><papertitle>Reinforcement Learning Based Coding Unit Early Termination Algorithm for High Efficiency Video Coding</papertitle>,
                            <br>N. Li, Y. Zhang, L. Zhu, W. Luo, S. Kwong,<br>
                            <i>Journal of Visual Communication and Image Representation, vol. 60, pp. 276-286, 2019</i>
                            <br>
                            [<a href="papers/RL_Coding.pdf">PDF</a>] 
                            <p></p></li>  

                            <li><papertitle>Adversarial Spatio-Temporal Learning for Video Deblurring</papertitle>,
                              <br>K. Zhang+, W. Luo, Y. Zhong, L. Ma, W. Liu and H. Li,<br>
                              <i>IEEE Trans. on Image Processing (TIP), vol. 28, no. 1, pp. 291-301, 2019.</i>
                              <br>
                              [<a href="https://arxiv.org/abs/1804.00533">arXiv</a>]
                              [<a href="https://drive.google.com/file/d/1lBA-R32EYKsVn7ZYcfn1ibO8UdLFH_yI/view">Code</a>]
                              <p></p></li>  

                              <li><papertitle>Trajectories as Topics: Multi-Object Tracking by Topic Discovery</papertitle>,
                                <br>W. Luo, B. Stenger, X. Zhao, T-K. Kim,<br>
                                <i>IEEE Trans. on Image Processing (TIP), vol. 28, no. 1, pp. 240-252, 2019.</i>
                                <br>
                                [<a href="papers/TIP19.pdf">PDF</a>]
                                <p></p></li>  


                                <li><papertitle>AD-VAT: An Asymmetric Dueling Mechanism for Learning Visual Active Tracking</papertitle>,
                                  <br>F. Zhong+, P. Sun, W. Luo, T. Yan, Y. Wang,<br>
                                  <i>Neural Information Processing Systems (NIPS), workshop on Deep Reinforcement Learning, 2018.</i>
                                  <br>
                                  [<a href="papers/AD-VAT_de-anonymized.pdf">PDF</a>]
                                  <p></p></li>  

                          <li><papertitle>Bi-Real Net: Enhancing the Performance of 1-bit CNNs with Improved Representational Capability and Advanced Training Algorithm</papertitle>,
                            <br>Z. Liu+, B. Wu, W. Luo, X. Yang, W. Liu, K-T. Cheng,<br>
                            <i>European Conference on Computer Vision (ECCV), Germany, 2018.</i>
                            <br>
                            [<a href="papers/bi_real_net_eccv18.pdf">PDF</a>]
                            [<a href="https://github.com/liuzechun/Bi-Real-net">Code</a>]
                            <p></p></li>  

                       

                          <li><papertitle>End-to-end Active Object Tracking via Reinforcement Learning</papertitle>,
                          <br>W. Luo*, P. Sun*, F. Zhong, W. Liu, T. Zhang and Y. Wang,<br>
                          <i>International Conference on Machine Learning (ICML), Sweden, 2018.</i>
                          <br>
                          [<a href="papers/ICML2018.pdf">PDF</a>]
                          [<a href="https://sites.google.com/site/whluoimperial/active_tracking_icml2018">Project Page</a>]
                          [<a href="https://sites.google.com/site/whluoimperial/active_tracking_icml2018">Code</a>]
                          [<a href="https://drive.google.com/file/d/19Tz2rfF6i1CcTonOoS-xy1nIgx1qcQ9x/view">Demo</a>]
                          <p></p></li>  


                          <li><papertitle>Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</papertitle>,
                            <br>W. Xiong+, W. Luo, L. Ma, W. Liu and J. Luo,<br>
                            <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2018.</i>
                            <br>
                            [<a href="https://arxiv.org/abs/1709.07592">arXiv</a>]
                            [<a href="https://sites.google.com/site/whluoimperial/mdgan">Project Page</a>]
                            [<a href="https://github.com/weixiong-ur/mdgan">Code</a>]
                            [<a href="https://drive.google.com/file/d/1xWLiU-MBGN7MrsFHQm4_yXmfHBsMbJQo/view">Dataset</a>]
                            <p></p></li>  


                            <li><papertitle>Real-Time Neural Style Transfer for Videos</papertitle>,
                              <br>H. Huang+, H. Wang, W. Luo, L. Ma, W. Jiang, X. Zhu, Z. Li, W. Liu,<br>
                              <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), USA, 2017.</i>
                              <br>
                              [<a href="papers/cvpr17.pdf">PDF</a>]
                              <p></p></li> 

                                                                                                                 
                              <li><papertitle>Instant Coherent Group Motion Filtering by Group Motion Representations</papertitle>,
                                <br>N. Li, Y. Zhang, W. Luo, N. Guo,<br>
                                <i>Neurocomputing, vol. 266, pp. 304-314, 2017.</i>
                                <br>
                                [<a href="papers/Instant coherent group motion filtering by group motion representations.pdf">PDF</a>]
                                <p></p></li>  


                              <li><papertitle>Automatic Topic Discovery for Multi-object Tracking</papertitle>,
                                <br>W. Luo, B. Stenger, X. Zhao, T-K. Kim,<br>
                                <i>Proc. of the Association for the Advancement of Artificial Intelligence (AAAI), Austin, Texas, USA, 2015. (<strong>Oral</strong>)</i>
                                <br>
                                [<a href="papers/aaai15.pdf">PDF</a>]
                                <p></p></li>  




                            <li><papertitle>Bi-label Propagation for Generic Multiple Object Tracking</papertitle>,
                              <br>W. Luo, T-K. Kim, B. Stenger, X. Zhao, R. Cipolla,<br>
                              <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Columbus, Ohio, USA, 2014.</i>
                              <br>
                              [<a href="papers/cvpr14_1.pdf">PDF</a>]
                              <p></p></li> 

  
                                            
                              <li><papertitle>Unified Face Analysis by Iterative Multi-Output Random Forests</papertitle>,
                                <br>X. Zhao, T-K. Kim, W. Luo,<br>
                                <i>Proc. of IEEE Conf. on Computer Vision and Pattern Recognition (CVPR), Columbus, Ohio, USA, 2014.</i>
                                <br>
                                [<a href="papers/cvpr14_2.pdf">PDF</a>] 
                                <p></p></li>  

                                                            
                              <li><papertitle>Generic Object Crowd Tracking by Multi-Task Learning</papertitle>,
                                <br>W. Luo, T-K. Kim,<br>
                                <i>Proc. of British Machine Vision Conference (BMVC), Bristol, UK, 2013.</i>
                                <br>
                                [<a href="papers/bmvc13.pdf">PDF</a>]
                                <p></p></li>  

                                                                                                     
                                <li><papertitle>Active Contour-Based Visual Tracking by Integrating Colors, Shapes and Motions</papertitle>,
                                  <br>W. Hu, X. Zhou, W. Li, W. Luo, X. Zhang, S. Maybank,<br>
                                  <i>IEEE Trans. on Image Processing (TIP), vol. 22, no. 5, pp. 1778-1792, 2013.</i>
                                  <br>
                                  [<a href="papers/TIP13.pdf">PDF</a>]
                                  <p></p></li>  


                                  <li><papertitle>Single and Multiple Object Tracking Using Log-Euclidean Riemannian Subspace and Block-Division Appearance Model</papertitle>,
                                    <br>W. Hu, X. Li, W. Luo, X. Zhang, S. Maybank, Z. Zhang,<br>
                                    <i>IEEE Trans. on Pattern Analysis and Machine Intelligence (TPAMI), vol. 34, no. 12, pp. 2420-2440, 2012.</i>
                                    <br>
                                    [<a href="papers/PAMI12.pdf">PDF</a>]
                                    <p></p></li>  


                                   

                                    <li><papertitle>Semantic Shape Similarity Based Contour Tracking Evaluation</papertitle>,
                                      <br>X. Zhang, W. Luo, L. Zhao, W. Li, W. Hu,<br>
                                      <i>Optical Engineering, 2011.</i>
                                      <br>
                                      <p></p></li>



                                <li><papertitle>Robust Visual Tracking via Transfer Learning</papertitle>,
                                  <br>W. Luo, X. Li, W. Li, W. Hu,<br>
                                  <i>IEEE International Conference on Image Processing (ICIP), 2011.</i>
                                  <br>
                                  <p></p></li>  


                                  <li><papertitle>Efficient Block-division Model for Robust Multiple Object Tracking</papertitle>,
                                    <br>W. Luo, X. Zhang, Y. Liu, X. Li, W. Hu, W. Li,<br>
                                    <i>IEEE International Conference on Acoustics,Speech, and Signal Processing (ICASSP), 2011.</i>
                                    <br>
                                    <p></p></li>  
    
                                                                
                                    <li><papertitle>Robust Object Tracking with Boosted Discriminative Model via Graph Embedding</papertitle>,
                                      <br>W. Li, X. Zhang, W. Luo, W. Hu, H. Ling, O. Wu,<br>
                                      <i>ICCV Workshops, 2011.</i>
                                      <br>
                                      <p></p></li>  
                                
     
                                      <li><papertitle>Probabilistic Index Histogram for Robust Object Tracking</papertitle>,
                                        <br>W. Li, X. Zhang, N. Xie, W. Hu, W. Luo, H. Ling,<br>
                                        <i>ACCV Workshops, 2010.</i>
                                        <br>
                                        <p></p></li>  
        



                                        <br>


                              <div class="section">
                               <h2>Tech Report</h2>
                              <div class="research">
                                
                                
                                <papertitle>Transferring Image-CLIP to Video-Text Retrieval via Temporal Relations</papertitle>,
                                <br>H. Fang, P. Xiong, L. Xu, W. Luo,<br>
                                <i>2022.</i>	
                                <br>
                                <p></p>


                                <papertitle>Hierarchical Contrastive Learning for Single Image Dehazing</papertitle>,
                                <br>T. Wang, G. Tao, T. Shen, W. Lu, K. Zhang, W. Luo, T. Lu,<br>
                                <i>2022.</i>	
                                <br>
                                <p></p>


                                <papertitle>Multi-Prior Learning via Neural Architecture Search for Blind Face Restoration</papertitle>,
                                <br>Y. Yu, P. Zhang, K. Zhang, W. Luo, C. Li, Y. Yuan, G. Wang,<br>
                                <i>arXiv:2206.13962, 2022.</i>	
                                <br>
                                [<a href="https://arxiv.org/abs/2206.13962">arXiv</a>]
                                <p></p>

                                
                                <papertitle>Blind Face Restoration: Benchmark Datasets and a Baseline Model</papertitle>,
                                <br>P. Zhang, K. Zhang, W. Luo, C. Li, G. Wang,<br>
                                <i>	arXiv:2206.03697, 2022.</i>	
                                <br>
                               [<a href="https://arxiv.org/abs/2206.03697">arXiv</a>]
                                <p></p>


                                <papertitle>Few-shot Object Counting with Similarity-Aware Feature Enhancement</papertitle>,
                                <br>Z. You, Y. Shen, K. Yang, W. Luo, X. Lu, L. Cui, X. Le,<br>
                                <i>	arXiv:2201.08959, 2022.</i>
                                <br>
                               [<a href="https://arxiv.org/abs/2201.08959">arXiv</a>]
                                <p></p>

                              

             
                                <papertitle>Benchmarking Deep Deblurring Algorithms: A Large-Scale Multi-Cause Dataset and A New Baseline Model</papertitle>,
                                <br>K. Zhang, W. Luo, W. Ren, B. Stenger, W. Liu, H. Li, M. Yang,<br>
                                <i>	arXiv:2112.00234, 2021.</i>
                                <br>
                               [<a href="https://arxiv.org/abs/2112.00234">arXiv</a>]
                                <p></p>



                                <papertitle>Look Closer to Ground Better: Weakly-Supervised Temporal Grounding of Sentence in Video</papertitle>,
                                     <br>Z. Chen+, L. Ma, W. Luo, P. Tang, K.-Y. K. Wong,<br>
                                     <i>arXiv: 2001.09308, 2020.</i>
                                     <br>
                                    [<a href="https://arxiv.org/abs/2001.09308">arXiv</a>]
                                <p></p>


                                </div>

                                <br>
                                 <div class="section">
                                   <h2>Thesis</h2>
                                   <div class="research">

                                    <papertitle>Generic Multiple Object Tracking</papertitle>, W. Luo, Dept. of Electrical and Electronic Engineering, Imperial College London, 2016.
                                      [<a href="papers/Luo-W-2016-PhD-Thesis.pdf">PDF</a>]
                                    <p></p> 
                                </div>

                                
          </ol>


          <br><br>





      </td>
    </tr>
  </table>
</body>

</html>
