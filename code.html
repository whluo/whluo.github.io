<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Wenhan Luo - Code</title>
  
  <meta name="author" content="Jon Barron">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  



        
        
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                
              </p>
            

        
            </td>
          </tr>
        </tbody></table>
        
        
        <br><br>
        <papertitle>Liquid Warping GAN: A Unified Framework for Human Motion Imitation, Appearance Transfer and Novel View Synthesis</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for our ICCV2019 paper.</p>
        
        [<a href="https://github.com/svip-lab/impersonator">Code</a>]
        
        <p></p>


        <br><br>
        <papertitle>Bi-Real Net: Binarizing Deep Network towards Real-Network Performance</papertitle>
       
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the Bi-Real net of our IJCV2019 paper.</p>
        
        [<a href="https://github.com/liuzechun/Bi-Real-net">Code</a>]
        <p></p>

        <br><br>
        <papertitle>Weakly-Supervised Spatio-Temporally Grounding Natural Sentence in Video</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the spatio-temporal grounding of our ACL2019 paper.</p>
        
        [<a href="https://github.com/zfchenUnique/WSSTG">Code</a>]
        <p></p>



        <br><br>
        <papertitle>AD-VAT: An Asymmetric Dueling Mechanism for Learning Visual Active Tracking</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the visual active tracking in our ICLR2019 paper.</p>
        
        [<a href="https://github.com/zfw1226/active_tracking_rl">Code</a>]
        <p></p>

        <br><br>
        <papertitle>Learning to Compose Dynamic Tree Structures for Visual Contexts</papertitle>
       
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for scene graph generation in our CVPR2019 paper.</p>
        
        [<a href="https://github.com/KaihuaTang/VCTree-Scene-Graph-Generation">Code</a>]
        <p></p>


        <br><br>
        <papertitle>Learning to Generate Time-Lapse Videos Using Multi-Stage Dynamic Generative Adversarial Networks</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the MDGAN in our CVPR2018 paper.</p>
        
        [<a href="https://github.com/weixiong-ur/mdgan">Code</a>]
        <p></p>

        <br><br>
        <papertitle>Bi-Real Net: Enhancing the Performance of 1-bit CNNs with Improved Representational Capability and Advanced Training Algorithm</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the Bi-Real net in our ECCV2018 paper.</p>
        
        [<a href="https://github.com/liuzechun/Bi-Real-net">Code</a>]
        <p></p>


        <br><br>
        <papertitle>End-to-end Active Tracking via Reinforcement Learning</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the active tracking in our ICML2018 paper. Check the project page for the code.</p>
        
        [<a href="https://sites.google.com/site/whluoimperial/active_tracking_icml2018">Code</a>]
        <p></p>



        <br><br>
        <papertitle>Tracker Based on Riemannian Subspace Learning</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is for the single object tracking of our PAMI paper. The code is based on David Ross’ matlab code for object tracking by incremental learning. There are some mexw32/mexw64 format files, which are compiled in my PC. If they do not work in your PC, you should install C or C++ compilers in your matlab and compile the C files dependently in your PC to get your mexw32/mexw64 format files. For details, please see <a href="https://uk.mathworks.com/help/matlab/ref/mex.html">here</a>. Then you can run it after customizing your file paths.
        I hope the code can help to understand our paper. Questions regarding the code may be directed to Prof. Xi Li (xilizju AT zju.edu.cn) or me (whluo.china AT gmail.com). Your help is highly appreciated.</p>
        [<a href="https://github.com/whluo/Log_Euclidean_Riemannian_Subspace_Learning">Code</a>]
        <p></p>

        <br><br>
        <papertitle>A Tool for Getting Ground-truth Cutout</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This tool helps to get groundtruth for quantitative analysis of object tracking method. Note: read the txt file “readme.txt” first before using it.</p>
        [<a href="https://github.com/whluo/A-Tool-for-Getting-Ground-truth-Cutout">Code</a>]
        <p></p>

        <br><br>
        <papertitle>Matlab implementation for Multiple Instance Learning (MIL) tracker</papertitle>
        
        <p style="text-align:justify; text-justify:inter-ideograph;">This code is the Matlab implementation of visual tracker based on multiple instance learning by Babenko et al.</p>
        [<a href="https://github.com/whluo/MILTracker_Matlab_Version">Code</a>]
        <p></p>



        <br><br>


      </td>
    </tr>
  </table>
</body>

</html>
